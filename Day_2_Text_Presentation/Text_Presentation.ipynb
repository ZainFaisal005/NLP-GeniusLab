{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Presentation in NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tweet_Content\n",
       "0  im getting on borderlands and i will murder yo...\n",
       "1  I am coming to the borders and I will kill you...\n",
       "2  im getting on borderlands and i will kill you ...\n",
       "3  im coming on borderlands and i will murder you...\n",
       "4  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_training.csv', usecols=['Tweet_Content'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74682, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OneHotEncoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Tweet_Content'])\n",
    "\n",
    "texts = df['Tweet_Content'].tolist()\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "onehot_encoded = tokenizer.texts_to_matrix(texts, mode='binary')\n",
    "\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bag of Words with n grams**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uni gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['tweet_content']\n",
      "\n",
      "Bag of Words matrix:\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "print(\"\\nBag of Words matrix:\")\n",
    "print(bow_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bi gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    preprocessed_text = ' '.join(filtered_tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "df['Tweet_Content'] = df['Tweet_Content'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00 125' '00 borderlands' '000 grant' ... 'حبيت اللعبه' 'خلاص unk'\n",
      " 'خلاص حبيت']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 8946)\t1\n",
      "  (0, 7492)\t1\n",
      "  (0, 2454)\t1\n",
      "  (1, 3793)\t1\n",
      "  (1, 2649)\t1\n",
      "  (2, 8946)\t1\n",
      "  (2, 7492)\t1\n",
      "  (2, 2415)\t1\n",
      "  (3, 2454)\t1\n",
      "  (3, 8937)\t1\n",
      "  (3, 3792)\t1\n",
      "  (4, 8946)\t1\n",
      "  (4, 7492)\t1\n",
      "  (4, 2454)\t1\n",
      "  (5, 8946)\t1\n",
      "  (5, 7492)\t1\n",
      "  (5, 2454)\t1\n",
      "  (6, 15888)\t1\n",
      "  (6, 8784)\t1\n",
      "  (6, 10720)\t1\n",
      "  (6, 15705)\t1\n",
      "  (6, 6910)\t1\n",
      "  (6, 9510)\t1\n",
      "  (6, 8819)\t1\n",
      "  (6, 2339)\t1\n",
      "  :\t:\n",
      "  (4950, 19409)\t1\n",
      "  (4950, 7496)\t1\n",
      "  (4950, 5196)\t1\n",
      "  (4950, 3526)\t1\n",
      "  (4951, 9641)\t1\n",
      "  (4951, 8811)\t1\n",
      "  (4951, 1082)\t2\n",
      "  (4951, 1052)\t1\n",
      "  (4951, 17883)\t1\n",
      "  (4951, 9690)\t1\n",
      "  (4951, 15210)\t1\n",
      "  (4951, 8652)\t1\n",
      "  (4951, 632)\t1\n",
      "  (4951, 2945)\t1\n",
      "  (4951, 17336)\t1\n",
      "  (4951, 323)\t1\n",
      "  (4951, 17334)\t1\n",
      "  (4951, 278)\t1\n",
      "  (4951, 19644)\t1\n",
      "  (4951, 2946)\t1\n",
      "  (4951, 15648)\t1\n",
      "  (4951, 19409)\t1\n",
      "  (4951, 7496)\t1\n",
      "  (4951, 5196)\t1\n",
      "  (4951, 3526)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tri gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00 125 euro' '00 borderlands great' '000 grant fqc' ...\n",
      " 'خلاص unk اللعبه' 'خلاص حبيت bin' 'خلاص حبيت اللعبه']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 10867)\t1\n",
      "  (0, 9109)\t1\n",
      "  (1, 4768)\t1\n",
      "  (2, 10867)\t1\n",
      "  (2, 9108)\t1\n",
      "  (3, 10855)\t1\n",
      "  (3, 4766)\t1\n",
      "  (4, 10867)\t1\n",
      "  (4, 9109)\t1\n",
      "  (5, 10867)\t1\n",
      "  (5, 9109)\t1\n",
      "  (6, 19153)\t1\n",
      "  (6, 10650)\t1\n",
      "  (6, 13033)\t1\n",
      "  (6, 18957)\t1\n",
      "  (6, 8362)\t1\n",
      "  (6, 11497)\t1\n",
      "  (6, 10725)\t1\n",
      "  (6, 2828)\t1\n",
      "  (6, 7291)\t1\n",
      "  (6, 13255)\t1\n",
      "  (6, 14793)\t1\n",
      "  (6, 7407)\t1\n",
      "  (6, 4146)\t1\n",
      "  (6, 5652)\t1\n",
      "  :\t:\n",
      "  (4950, 23391)\t1\n",
      "  (4950, 9113)\t1\n",
      "  (4950, 6378)\t1\n",
      "  (4950, 10696)\t1\n",
      "  (4951, 1241)\t1\n",
      "  (4951, 21518)\t1\n",
      "  (4951, 11730)\t1\n",
      "  (4951, 18387)\t1\n",
      "  (4951, 10490)\t1\n",
      "  (4951, 748)\t1\n",
      "  (4951, 3691)\t1\n",
      "  (4951, 1272)\t1\n",
      "  (4951, 20831)\t1\n",
      "  (4951, 367)\t1\n",
      "  (4951, 1270)\t1\n",
      "  (4951, 20830)\t1\n",
      "  (4951, 317)\t1\n",
      "  (4951, 11669)\t1\n",
      "  (4951, 23695)\t1\n",
      "  (4951, 3692)\t1\n",
      "  (4951, 18887)\t1\n",
      "  (4951, 23391)\t1\n",
      "  (4951, 9113)\t1\n",
      "  (4951, 6378)\t1\n",
      "  (4951, 10696)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3, 3))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quad gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00 125 euro ift' '00 borderlands great week' '000 grant fqc bri' ...\n",
      " 'خلاص unk اللعبه callofduty' 'خلاص حبيت bin اللعبه'\n",
      " 'خلاص حبيت اللعبه callofduty']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 11358)\t1\n",
      "  (2, 11357)\t1\n",
      "  (3, 11347)\t1\n",
      "  (4, 11358)\t1\n",
      "  (5, 11358)\t1\n",
      "  (6, 20151)\t1\n",
      "  (6, 11195)\t1\n",
      "  (6, 13626)\t1\n",
      "  (6, 19934)\t1\n",
      "  (6, 8784)\t1\n",
      "  (6, 12017)\t1\n",
      "  (6, 11229)\t1\n",
      "  (6, 2943)\t1\n",
      "  (6, 7662)\t1\n",
      "  (6, 13853)\t1\n",
      "  (6, 15477)\t1\n",
      "  (6, 7786)\t1\n",
      "  (6, 4392)\t1\n",
      "  (6, 5995)\t1\n",
      "  (6, 13586)\t1\n",
      "  (6, 23358)\t1\n",
      "  (6, 16259)\t1\n",
      "  (6, 15931)\t1\n",
      "  (6, 11390)\t1\n",
      "  (6, 23046)\t1\n",
      "  :\t:\n",
      "  (4950, 3894)\t1\n",
      "  (4950, 19864)\t1\n",
      "  (4950, 24507)\t1\n",
      "  (4950, 9584)\t1\n",
      "  (4950, 6745)\t1\n",
      "  (4951, 1309)\t1\n",
      "  (4951, 22555)\t1\n",
      "  (4951, 12262)\t1\n",
      "  (4951, 19360)\t1\n",
      "  (4951, 11025)\t1\n",
      "  (4951, 801)\t1\n",
      "  (4951, 3893)\t1\n",
      "  (4951, 1336)\t1\n",
      "  (4951, 21901)\t1\n",
      "  (4951, 388)\t1\n",
      "  (4951, 1335)\t1\n",
      "  (4951, 21900)\t1\n",
      "  (4951, 335)\t1\n",
      "  (4951, 12204)\t1\n",
      "  (4951, 24829)\t1\n",
      "  (4951, 3894)\t1\n",
      "  (4951, 19864)\t1\n",
      "  (4951, 24507)\t1\n",
      "  (4951, 9584)\t1\n",
      "  (4951, 6745)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(4, 4))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uni Bi gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00' '00 125' '00 borderlands' ... 'خلاص' 'خلاص unk' 'خلاص حبيت']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 11249)\t1\n",
      "  (0, 9437)\t1\n",
      "  (0, 2865)\t1\n",
      "  (0, 14492)\t1\n",
      "  (0, 11261)\t1\n",
      "  (0, 9441)\t1\n",
      "  (0, 3084)\t1\n",
      "  (1, 4764)\t1\n",
      "  (1, 3280)\t1\n",
      "  (1, 11938)\t1\n",
      "  (1, 4767)\t1\n",
      "  (1, 3283)\t1\n",
      "  (2, 11249)\t1\n",
      "  (2, 9437)\t1\n",
      "  (2, 2865)\t1\n",
      "  (2, 11261)\t1\n",
      "  (2, 9441)\t1\n",
      "  (2, 11938)\t1\n",
      "  (2, 3045)\t1\n",
      "  (3, 11249)\t1\n",
      "  (3, 2865)\t1\n",
      "  (3, 14492)\t1\n",
      "  (3, 3084)\t1\n",
      "  (3, 4764)\t1\n",
      "  (3, 11252)\t1\n",
      "  :\t:\n",
      "  (4951, 12293)\t1\n",
      "  (4951, 19280)\t1\n",
      "  (4951, 10876)\t1\n",
      "  (4951, 866)\t1\n",
      "  (4951, 3683)\t2\n",
      "  (4951, 437)\t1\n",
      "  (4951, 367)\t1\n",
      "  (4951, 9474)\t1\n",
      "  (4951, 22683)\t1\n",
      "  (4951, 12294)\t1\n",
      "  (4951, 19281)\t1\n",
      "  (4951, 10877)\t1\n",
      "  (4951, 867)\t1\n",
      "  (4951, 3684)\t1\n",
      "  (4951, 22001)\t1\n",
      "  (4951, 438)\t1\n",
      "  (4951, 21999)\t1\n",
      "  (4951, 368)\t1\n",
      "  (4951, 24830)\t1\n",
      "  (4951, 3685)\t1\n",
      "  (4951, 19876)\t1\n",
      "  (4951, 24539)\t1\n",
      "  (4951, 9445)\t1\n",
      "  (4951, 6639)\t1\n",
      "  (4951, 4472)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bi Tri gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00 125' '00 125 euro' '00 borderlands' ... 'خلاص حبيت' 'خلاص حبيت bin'\n",
      " 'خلاص حبيت اللعبه']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 19813)\t1\n",
      "  (0, 16600)\t1\n",
      "  (0, 5455)\t1\n",
      "  (0, 19814)\t1\n",
      "  (0, 16602)\t1\n",
      "  (1, 8561)\t1\n",
      "  (1, 5977)\t1\n",
      "  (1, 8562)\t1\n",
      "  (2, 19813)\t1\n",
      "  (2, 16600)\t1\n",
      "  (2, 19814)\t1\n",
      "  (2, 5366)\t1\n",
      "  (2, 16601)\t1\n",
      "  (3, 5455)\t1\n",
      "  (3, 19792)\t1\n",
      "  (3, 8558)\t1\n",
      "  (3, 19793)\t1\n",
      "  (3, 8559)\t1\n",
      "  (4, 19813)\t1\n",
      "  (4, 16600)\t1\n",
      "  (4, 5455)\t1\n",
      "  (4, 19814)\t1\n",
      "  (4, 16602)\t1\n",
      "  (5, 19813)\t1\n",
      "  (5, 16600)\t1\n",
      "  :\t:\n",
      "  (4951, 42800)\t1\n",
      "  (4951, 16609)\t1\n",
      "  (4951, 11574)\t1\n",
      "  (4951, 7895)\t1\n",
      "  (4951, 2294)\t1\n",
      "  (4951, 39402)\t1\n",
      "  (4951, 21421)\t1\n",
      "  (4951, 33598)\t1\n",
      "  (4951, 19143)\t1\n",
      "  (4951, 1381)\t1\n",
      "  (4951, 6637)\t1\n",
      "  (4951, 2355)\t1\n",
      "  (4951, 38168)\t1\n",
      "  (4951, 691)\t1\n",
      "  (4951, 2353)\t1\n",
      "  (4951, 38165)\t1\n",
      "  (4951, 596)\t1\n",
      "  (4951, 21311)\t1\n",
      "  (4951, 43340)\t1\n",
      "  (4951, 6639)\t1\n",
      "  (4951, 34536)\t1\n",
      "  (4951, 42801)\t1\n",
      "  (4951, 16610)\t1\n",
      "  (4951, 11575)\t1\n",
      "  (4951, 19508)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tri Quad gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words and n-grams):\n",
      "['00 125 euro' '00 125 euro ift' '00 borderlands great' ...\n",
      " 'خلاص حبيت bin اللعبه' 'خلاص حبيت اللعبه' 'خلاص حبيت اللعبه callofduty']\n",
      "\n",
      "Bag of Words matrix (sparse format):\n",
      "  (0, 22224)\t1\n",
      "  (0, 18689)\t1\n",
      "  (0, 22226)\t1\n",
      "  (1, 9866)\t1\n",
      "  (2, 22224)\t1\n",
      "  (2, 18688)\t1\n",
      "  (2, 22225)\t1\n",
      "  (3, 22202)\t1\n",
      "  (3, 9863)\t1\n",
      "  (3, 22203)\t1\n",
      "  (4, 22224)\t1\n",
      "  (4, 18689)\t1\n",
      "  (4, 22226)\t1\n",
      "  (5, 22224)\t1\n",
      "  (5, 18689)\t1\n",
      "  (5, 22226)\t1\n",
      "  (6, 39304)\t1\n",
      "  (6, 21845)\t1\n",
      "  (6, 26659)\t1\n",
      "  (6, 38891)\t1\n",
      "  (6, 17146)\t1\n",
      "  (6, 23514)\t1\n",
      "  (6, 21954)\t1\n",
      "  (6, 5771)\t1\n",
      "  (6, 14953)\t1\n",
      "  :\t:\n",
      "  (4951, 38751)\t1\n",
      "  (4951, 47898)\t1\n",
      "  (4951, 18697)\t1\n",
      "  (4951, 13123)\t1\n",
      "  (4951, 21920)\t1\n",
      "  (4951, 2551)\t1\n",
      "  (4951, 44074)\t1\n",
      "  (4951, 23993)\t1\n",
      "  (4951, 37748)\t1\n",
      "  (4951, 21516)\t1\n",
      "  (4951, 1550)\t1\n",
      "  (4951, 7585)\t1\n",
      "  (4951, 2609)\t1\n",
      "  (4951, 42733)\t1\n",
      "  (4951, 756)\t1\n",
      "  (4951, 2606)\t1\n",
      "  (4951, 42731)\t1\n",
      "  (4951, 653)\t1\n",
      "  (4951, 23874)\t1\n",
      "  (4951, 48525)\t1\n",
      "  (4951, 7587)\t1\n",
      "  (4951, 38752)\t1\n",
      "  (4951, 47899)\t1\n",
      "  (4951, 18698)\t1\n",
      "  (4951, 13124)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3, 4))\n",
    "\n",
    "bow_matrix = vectorizer.fit_transform(df['Tweet_Content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (words and n-grams):\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nBag of Words matrix (sparse format):\")\n",
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tf- Idf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (terms):\n",
      "['tweet_content']\n",
      "\n",
      "TF-IDF matrix:\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df)\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Feature names (terms):\")\n",
    "print(feature_names)\n",
    "print(\"\\nTF-IDF matrix:\")\n",
    "print(tfidf_matrix.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
